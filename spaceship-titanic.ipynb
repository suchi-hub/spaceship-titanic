{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_null_filler(dataframe):\n",
    "    for name in dataframe.columns:\n",
    "        dataframe.loc[dataframe[name].isnull(), name] = train[name].value_counts().index[0] \n",
    "# tf.keras.utils.get_file -> used to get file from web\n",
    "train = pd.read_csv(os.path.join(os.getcwd(),'train.csv'))\n",
    "train['target'] = np.where(train.Transported, 1,0)\n",
    "train = train.drop(columns=['PassengerId', 'Cabin', 'Name', 'Transported'])\n",
    "most_common_null_filler(train)\n",
    "# train = train.convert_dtypes(convert_integer=False)\n",
    "train[['CryoSleep', 'VIP']] = train[['CryoSleep', 'VIP']].astype(dtype='bool')\n",
    "\n",
    "test = pd.read_csv(os.path.join(os.getcwd(),'test.csv'))\n",
    "test = test.drop(columns=['PassengerId', 'Cabin', 'Name'])\n",
    "most_common_null_filler(test)\n",
    "test[['CryoSleep', 'VIP']] = test[['CryoSleep', 'VIP']].astype(dtype='bool')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet  CryoSleep    Destination   Age    VIP  RoomService  \\\n",
       "0        Europa      False    TRAPPIST-1e  39.0  False          0.0   \n",
       "1         Earth      False    TRAPPIST-1e  24.0  False        109.0   \n",
       "2        Europa      False    TRAPPIST-1e  58.0   True         43.0   \n",
       "3        Europa      False    TRAPPIST-1e  33.0  False          0.0   \n",
       "4         Earth      False    TRAPPIST-1e  16.0  False        303.0   \n",
       "...         ...        ...            ...   ...    ...          ...   \n",
       "8688     Europa      False    55 Cancri e  41.0   True          0.0   \n",
       "8689      Earth       True  PSO J318.5-22  18.0  False          0.0   \n",
       "8690      Earth      False    TRAPPIST-1e  26.0  False          0.0   \n",
       "8691     Europa      False    55 Cancri e  32.0  False          0.0   \n",
       "8692     Europa      False    TRAPPIST-1e  44.0  False        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck  target  \n",
       "0           0.0           0.0     0.0     0.0       0  \n",
       "1           9.0          25.0   549.0    44.0       1  \n",
       "2        3576.0           0.0  6715.0    49.0       0  \n",
       "3        1283.0         371.0  3329.0   193.0       0  \n",
       "4          70.0         151.0   565.0     2.0       1  \n",
       "...         ...           ...     ...     ...     ...  \n",
       "8688     6819.0           0.0  1643.0    74.0       0  \n",
       "8689        0.0           0.0     0.0     0.0       0  \n",
       "8690        0.0        1872.0     1.0     0.0       1  \n",
       "8691     1049.0           0.0   353.0  3235.0       0  \n",
       "8692     4688.0           0.0     0.0    12.0       1  \n",
       "\n",
       "[8693 rows x 11 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input pipeline. Tensorflow supports dictionary\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    labels = df.pop('target')\n",
    "    df = {key: np.array(value)[:, tf.newaxis] for key, value in df.items()}\n",
    "    ds = tf.data.Dataset.from_tensor_slices((df, labels))\n",
    "    if shuffle==True:\n",
    "        ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size=batch_size)\n",
    "    ds = ds.prefetch(buffer_size=1000)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this batch size for testing\n",
    "train_ds = df_to_dataset(train, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test input pipeline\n",
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print(train_features['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "    # create a layer for normalization\n",
    "    normalizer = tf.keras.layers.Normalization(axis=None)\n",
    "\n",
    "    # create a dataset that yields the train_features\n",
    "    feature_ds = dataset.map(lambda x,y: x[name])\n",
    "\n",
    "    # learn the statistics of the feature\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normalization\n",
    "food_court_col = train_features['FoodCourt']\n",
    "layer = get_normalization_layer('FoodCourt', train_ds)\n",
    "layer(food_court_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    # Create a layer that turns strings into integer indices\n",
    "    if dtype=='string':\n",
    "        index = tf.keras.layers.StringLookup(max_tokens=max_tokens)\n",
    "    # Otherwise, create a layer that turns integers into integer indices\n",
    "    else:\n",
    "        index = tf.keras.layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "    # Create a dataset that yeilds the features\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the dataset indices\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # create the encoding layer for the integer indices\n",
    "    encoding = tf.keras.layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "                                                \n",
    "    # create multi-hot-encoding from the encodings. The lambda function captures the\n",
    "    # layer, so you can use them, or include them in the Keras Functional model later.\n",
    "    return lambda feature: encoding(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test categorical encoding\n",
    "test_homeplanet_col = train_features['HomePlanet']\n",
    "test_homeplanet_layer = get_category_encoding_layer('HomePlanet', train_ds, 'string')\n",
    "test_homeplanet_layer(test_homeplanet_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bigger batch size data\n",
    "batch_size = 64\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "# create input and output placeholders for model (encode numberical and categorical data)\n",
    "# group them in 1 list\n",
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "for header in ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']:\n",
    "    numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs.append(numeric_col)\n",
    "    encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category encoded features\n",
    "age_col = tf.keras.Input(shape=(1,), name='Age')\n",
    "encoding_layer = get_category_encoding_layer(name='Age', dataset=train_ds, dtype='float32', max_tokens=5)\n",
    "encoded_age_col = encoding_layer(age_col)\n",
    "all_inputs.append(age_col)\n",
    "encoded_features.append(encoded_age_col)\n",
    "\n",
    "for header in ['CryoSleep','VIP']:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='float32')\n",
    "    encoding_layer = get_category_encoding_layer(name=header, dataset=train_ds, dtype='bool')\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)\n",
    "\n",
    "for header in ['HomePlanet', 'Destination']:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "    encoding_layer = get_category_encoding_layer(name=header, dataset=train_ds, dtype='string', max_tokens=5)\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(units=256, activation='relu')(all_features)\n",
    "x = tf.keras.layers.Dense(units=128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=16, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "output = tf.keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the model tree structure\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 2s 3ms/step - loss: 0.4867 - accuracy: 0.7689\n",
      "Epoch 2/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7880\n",
      "Epoch 3/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7924\n",
      "Epoch 4/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7943\n",
      "Epoch 5/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7950\n",
      "Epoch 6/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7998\n",
      "Epoch 7/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7985\n",
      "Epoch 8/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7949\n",
      "Epoch 9/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7968\n",
      "Epoch 10/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7950\n",
      "Epoch 11/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7918\n",
      "Epoch 12/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7967\n",
      "Epoch 13/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7955\n",
      "Epoch 14/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7997\n",
      "Epoch 15/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7988\n",
      "Epoch 16/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7981\n",
      "Epoch 17/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7985\n",
      "Epoch 18/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8008\n",
      "Epoch 19/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8024\n",
      "Epoch 20/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7987\n",
      "Epoch 21/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8006\n",
      "Epoch 22/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8016\n",
      "Epoch 23/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8021\n",
      "Epoch 24/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8020\n",
      "Epoch 25/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8048\n",
      "Epoch 26/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8025\n",
      "Epoch 27/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8021\n",
      "Epoch 28/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8043\n",
      "Epoch 29/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8054\n",
      "Epoch 30/30\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ebc1fbb910>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model\n",
    "model.fit(train_ds, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {name: np.array(value)[:, tf.newaxis] for name, value in test.items()}\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in test_ds.take(5):\n",
    "    print(element['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25/4277 [..............................] - ETA: 8s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4277/4277 [==============================] - 7s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=128, activation='relu', input_shape=[tensor_shape]),\n",
    "    tf.keras.layers.Dense(units=64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "model.fit(x_train, y_train\n",
    "          validation_data=[x_valid, y_valid],\n",
    "          epochs=100,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pred = np.round(prediction).flatten()\n",
    "submission_id = pd.read_csv(os.path.join(os.getcwd(),'test.csv'))\n",
    "submission_id = submission_id['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId': submission_id, 'Transported': submission_pred.astype('bool')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
